---
layout: ../../layouts/BlogLayout.astro
slug: mariogpt 
title: It's a me, MarioGPT! üçÑ
description: 
authors:
  - Lukas Rasocha 
  - Ludek Cizinsky
format: blog
tags:
  - mariogpt
  - game
  - procedural-content-generation
  - pcg
  - large-language-models
  - transformers
image: 
  src: /posts/mariogpt/mario.webp
  alt: MarioGPT 
published: 03/01/2023
---

Welcome! üôå This week we delved deeper into yer another domain where Large Language Models are starting to show their presence. [MarioGPT](https://arxiv.org/abs/2302.05981) is the first text-to-level machine learning model that was recently publised by Shyam Sudhakaran et. al and gained a lot of attention all over the world, reaching hundreds of ‚≠ê on github in just a few days. 

The usage of AI in games to automatically generate content is not at all a new concept. To generate levels that are challenging, correspond to the game mechanics but are still playable has been a challenge in the field of **Procedural Content Generation (PCG)** over a few decades. With traditional PCG methods we can go as far back as the 1980's where in rogue like games, PCG would create dungeons in **ASCII** and define rooms, hallways, monsters, and treasure to challenge the player.


<br/>

![ASCII level generated by PCG](/posts/mariogpt/ascii.png)

<br/>

Only over the last couple of years have we seen an increase in effort to incorporate the tools of **deep learning** into game level generation. Where for example **Generative Adversial Networks (GANs)** became quite popular due to their ability to create image-like creative content. What these methods lack, however, is a simple way for a game level designer to hold more freedom with regard to the specific characterstics of the levels
### üìê Architecture 

---

<br/>


<br/>

### üîÆ Key Takeaways

---

<br/>

**üåü State-Of-The-Art.** When trained at a large scale, Google's ViT pushed the boundary in image recognition performance on numerous benchmarks. In doing so, it started a new era of Transformer-based models in the computer vision field. We encourage you to try them out. They are open-sourced and accessible, for instance, on [Huggingface](https://huggingface.co/models?pipeline_tag=image-classification&sort=downloads).

<br/>

**ü§å Keep it Simple.** One thing about ViT we found especially remarkable: The researcher's self-proclaimed goal was to "_apply the standard Transformer architecture directly to images, with the fewest possible modifications_." This led to a model that, at its core, was not designed to handle image data (and its inherent features, like the strong local correlation of pixels). Our group was surprised how a model, inferior in capturing some of the intrinsic properties of its input data, still outperformed many of the most powerful convolutional neural networks specifically designed for image data. The takeaway from this is beautifully summarised by the research team:
**"Large-Scale Training Trumps Inductive Bias"**.

<br/>

**üñºÔ∏è Handling Medium-Sized Images.** One of the critical challenges when applying the Transformer architecture to images was deciding what constitutes a token. In the NLP domain, the definition is relatively straightforward. However, when dealing with image data treating each pixel as a single token does not scale as attention scores are computed pair-wise (quadratic running time) in each Transformer layer. One of the previous papers showed that a viable solution could be to split the image into 2x2 patches. This works for images with a small resolution. However, again scales poorly for images with higher resolution. Therefore, Google's ViT uses patches of size 16x16 pixels enabling the model to handle even medium-resolution images.

<br/>

**üÜò Limited to Image Recognition.** As of the paper's release, ViT is limited to image classification. How the architecture can be extended to other common computer vision tasks, like object detection or image segmentation, is yet to be explored.

### üì£ Stay in touch

---

That's it for this week. We hope you enjoyed reading this post. üòä To stay updated about our activities, make sure you give us a follow on [LinkedIn](https://www.linkedin.com/company/aitu-dk/) and [Subscribe to our Newsletter](https://aitu.group/#newsletter). Any questions or ideas for talks, collaboration, etc.? Drop us a message at [hello@aitu.group](mailto:hello@aitu.group).
